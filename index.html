<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Renato  Panda</title>
<meta name="description" content="A simple webpage describing my work and life.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- Theming-->




    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/honors/">
                honors
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/press/">
                press
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Renato   Panda</span>
    </h1>
     <p class="desc"><small><a href="https://www.cisuc.uc.pt" target="_blank">CISUC</a> - Centre for Informatics and Systems of the University of Coimbra.<br><a href="http://mir.dei.uc.pt" target="_blank">MIRlab</a> - Music Information Retrieval . CISUC<br>panda@dei.uc.pt.</small></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/prof_pic.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>I am a member at the Centre for Informatics and Systems of the University of Coimbra
(<a href="https://www.cisuc.uc.pt" target="\_blank">CISUC</a>), belonging to the Cognitive and Media Systems (CMS) group and the <a href="http://mir.dei.uc.pt/" target="\_blank">MIR</a> lab. I hold a Ph.D. in Information Science and Technology by the University of Coimbra (<a href="http://www.uc.pt/" target="\_blank">UC</a>). I have participated in 3 research projects and published several papers in international journals and conference proceedings.</p>

<p>My research interests are focused on pattern recognition, namely Music Emotion Recognition (MER) and Music Information Retrieval (MIR) from audio and lyrics. Additionally, I have also worked on applied research projects dealing with machine learning and modern software development patterns for different problems from health/well-being to tourism data.</p>

<p>During the 2019/2020 academic year I worked as an full time Assistant Professor (non-Tenure) at the Tomar Technology School (ESTT) of the Polytechnic Institute of Tomar (<a href="http://www.ipt.pt/" target="\_blank">IPT</a>). Previously I have worked at the same institution as a Teaching Assistant and have been a grant holder at <a href="https://www.cisuc.uc.pt" target="\_blank">CISUC</a>, as well as the Portuguese <a href="https://www.fct.pt" target="\_blank">FCT</a>.</p>

<p>In my free times I enjoy spending time with friends and family, physical exercise, comics, hiking, photography, genealogy, and spending time in side projects such as <a href="https://www.tosecdev.org/" target="\_blank">TOSEC</a> (The Old School Emulation Center).</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Nov 18, 2020</th>
          <td>
            
              Our TAFFC paper <em>Novel Audio Features for Music Emotion Recognition</em> has finally been published on IEEE Xplore (<a href="https://ieeexplore.ieee.org/document/8327886" target="\_blank">Volume: 11, Issue: 4, Oct.-Dec. 1 2020</a>)

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 28, 2020</th>
          <td>
            
              <a class="news-title" href="/news/fraunhofer_prize/">2nd prize @ Fraunhofer Challenge 2020 <img class="emoji" title=":trophy:" alt=":trophy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c6.png" height="20" width="20"></a>
            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 13, 2020</th>
          <td>
            
              Our paper <em>Audio Features for Music Emotion Recognition: a Survey</em> has been accepted in an upcoming issue of the IEEE Transactions on Affective Computing (<a href="https://doi.org/10.1109/TAFFC.2020.3032373" target="\_blank">early access</a>) <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TAFFC</abbr>
    
  
  </div>

  <div id="Panda2020" class="col-sm-8">
    
      <div class="title">Audio Features for Music Emotion Recognition: a Survey</div>
      <div class="author">
        
          
            
              
                <em>Panda, Renato</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.cisuc.uc.pt/en/people/ricardo-malheiro" target="_blank">Malheiro, Ricardo Manuel</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://eden.dei.uc.pt/~ruipedro/" target="_blank">Paiva, Rui Pedro</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Affective Computing</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9229494/" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
      <a href="/assets/pdf/papers/Panda,%20Malheiro,%20Paiva%20-%202020%20-%20Audio%20Features%20for%20Music%20Emotion%20Recognition%20a%20Survey.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The design of meaningful audio features is a key need to advance the state-of-the-art in Music Emotion Recognition (MER). This work presents a survey on the existing emotionally-relevant computational audio features, supported by the music psychology literature on the relations between eight musical dimensions (melody, harmony, rhythm, dynamics, tone color, expressivity, texture and form) and specific emotions. Based on this review, current gaps and needs are identified and strategies for future research on feature engineering for MER are proposed, namely ideas for computational audio features that capture elements of musical form, texture and expressivity that should be further researched. Finally, although the focus of this article is on classical feature engineering methodologies (based on handcrafted features), perspectives on deep learning-based approaches are discussed.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TAFFC</abbr>
    
  
  </div>

  <div id="Panda2018a" class="col-sm-8">
    
      <div class="title">Novel Audio Features for Music Emotion Recognition</div>
      <div class="author">
        
          
            
              
                <em>Panda, Renato</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.cisuc.uc.pt/en/people/ricardo-malheiro" target="_blank">Malheiro, Ricardo</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://eden.dei.uc.pt/~ruipedro/" target="_blank">Paiva, Rui Pedro</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Affective Computing</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://ieeexplore.ieee.org/document/8327886/" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
      <a href="/assets/pdf/papers/Panda,%20Malheiro,%20Paiva%20-%202020%20-%20Novel%20Audio%20Features%20for%20Music%20Emotion%20Recognition.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This work advances the music emotion recognition state-of-the-art by proposing novel emotionally-relevant audio features. We reviewed the existing audio features implemented in well-known frameworks and their relationships with the eight commonly defined musical concepts. This knowledge helped uncover musical concepts lacking computational extractors, to which we propose algorithms - namely related with musical texture and expressive techniques. To evaluate our work, we created a public dataset of 900 audio clips, with subjective annotations following Russell’s emotion quadrants. The existent audio features (baseline) and the proposed features (novel) were tested using 20 repetitions of 10-fold cross-validation. Adding the proposed features improved the F1-score to 76.4% (by 9%), when compared to a similar number of baseline-only features. Moreover, analysing the features relevance and results uncovered interesting relations, namely the weight of specific features and musical concepts to each emotion quadrant, and warrant promising new directions for future research in the field of music emotion recognition, interactive media, and novel music interfaces.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TAFFC</abbr>
    
  
  </div>

  <div id="Malheiro2018" class="col-sm-8">
    
      <div class="title">Emotionally-Relevant Features for Classification and Regression of Music Lyrics</div>
      <div class="author">
        
          
            
              
                
                  <a href="https://www.cisuc.uc.pt/en/people/ricardo-malheiro" target="_blank">Malheiro, Ricardo</a>,
                
              
            
          
        
          
            
              
                <em>Panda, Renato</em>,
              
            
          
        
          
            
              
                
                  Gomes, Paulo,
                
              
            
          
        
          
            
              
                
                  and <a href="https://eden.dei.uc.pt/~ruipedro/" target="_blank">Paiva, Rui Pedro</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Affective Computing – TAFFC</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="http://ieeexplore.ieee.org/document/7536113/" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
      <a href="/assets/pdf/papers/Malheiro%20et%20al.%20-%202018%20-%20Emotionally-Relevant%20Features%20for%20Classification%20and%20Regression%20of%20Music%20Lyrics.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This research addresses the role of lyrics in the music emotion recognition process. Our approach is based on several state of the art features complemented by novel stylistic, structural and semantic features. To evaluate our approach, we created a ground truth dataset containing 180 song lyrics, according to Russell’s emotion model. We conduct four types of experiments: regression and classification by quadrant, arousal and valence categories. Comparing to the state of the art features (ngrams - baseline), adding other features, including novel features, improved the F-measure from 69.9%, 82.7% and 85.6% to 80.1%, 88.3% and 90%, respectively for the three classification experiments. To study the relation between features and emotions (quadrants) we performed experiments to identify the best features that allow to describe and discriminate each quadrant. To further validate these experiments, we built a validation set comprising 771 lyrics extracted from the AllMusic platform, having achieved 73.6% F-measure in the classification by quadrants. We also conducted experiments to identify interpretable rules that show the relation between features and emotions and the relation among features. Regarding regression, results show that, comparing to similar studies for audio, we achieve a similar performance for arousal and a much better performance for valence.</p>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CMMR</abbr>
    
  
  </div>

  <div id="Panda2013a" class="col-sm-8">
    
      <div class="title">Multi-Modal Music Emotion Recognition: A New Dataset, Methodology and Comparative Analysis</div>
      <div class="author">
        
          
            
              
                <em>Panda, Renato</em>,
              
            
          
        
          
            
              
                
                  <a href="https://www.cisuc.uc.pt/en/people/ricardo-malheiro" target="_blank">Malheiro, Ricardo</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.researchgate.net/profile/Bruno_Rocha14" target="_blank">Rocha, Bruno</a>,
                
              
            
          
        
          
            
              
                
                  <a href="https://www.researchgate.net/profile/Luis_Oliveira10" target="_blank">Oliveira, António Pedro</a>,
                
              
            
          
        
          
            
              
                
                  and <a href="https://eden.dei.uc.pt/~ruipedro/" target="_blank">Paiva, Rui Pedro</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 10th International Symposium on Computer Music Multidisciplinary Research – CMMR 2013</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
      <a href="/assets/pdf/papers/Panda%20et%20al.%20-%202013%20-%20Multi-Modal%20Music%20Emotion%20Recognition%20A%20New%20Dataset,%20Methodology%20and%20Comparative%20Analysis.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose a multi-modal approach to the music emotion recognition (MER) problem, combining information from distinct sources, namely audio, MIDI and lyrics. We introduce a methodology for the automatic creation of a multi-modal music emotion dataset resorting to the AllMusic database, based on the emotion tags used in the MIREX Mood Classification Task. Then, MIDI files and lyrics corresponding to a sub-set of the obtained audio samples were gathered. The dataset was organized into the same 5 emotion clusters defined in MIREX. From the audio data, 177 standard features and 98 melodic features were extracted. As for MIDI, 320 features were collected. Finally, 26 lyrical features were extracted. We experimented with several supervised learning and feature selection strategies to evaluate the proposed multi-modal approach. Employing only standard audio features, the best attained performance was 44.3% (F-measure). With the multi-modal approach, results improved to 61.1%, using only 19 multi-modal features. Melodic audio features were particularly important to this improvement.</p>
    </div>
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%70%61%6E%64%61@%64%65%69.%75%63.%70%74"><i class="fas fa-envelope"></i></a>
  <a href="https://orcid.org/0000-0003-2539-5590" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
  <a href="https://scholar.google.com/citations?user=WT5afVUAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  <a href="https://www.scopus.com/authid/detail.uri?authorId=55354413900" target="_blank" title="Scopus Author"><i class="ai ai-scopus"></i></a>
  <a href="https://www.cienciavitae.pt/en/661A-31CC-8D19" target="_blank" title="CienciaVitae"><i class="ai ai-ciencia-vitae"></i></a>
  <a href="https://publons.com/a/AAK-7581-2020/" target="_blank" title="Publons"><i class="ai ai-publons"></i></a>
  <a href="https://www.researchgate.net/profile/Renato_Panda/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
  <a href="https://github.com/renatopanda" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  <a href="https://www.linkedin.com/in/renato-panda-a26b8424" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
  
  
  
  
  
  
</span>

      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2021 Renato  Panda.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: January 14, 2021.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
